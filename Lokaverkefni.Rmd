---
title: "Linear times at Ridgemont high"
author: "Bergrós Skúladóttir, Indriði Arnaldsson & Íris Aníta Eyþórsdóttir"
output:
    rmdformats::downcute:
      self_contained: true
      thumbnails: true
      lightbox: true
      gallery: false
      highlight: tango
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, message = F, warning = F, error = F)
```

```{css, echo=FALSE, class.output="scroll-100"}
.scroll-100 {
  max-height: 300px;
  overflow-y: auto;
  bakground-color:inherit;
}
pre[class] {
  max-height: 160px;
}
```

```{r}
library(tidyverse)
library(ggridges)
library(data.table)
library(gridExtra)
library(corrplot)
library(kableExtra)
library(glmnet)
options(scipen = 999)
library(randomForest)
library(gbm)
library(scales)
library(tree)
library(caret)
library(Metrics)
library(grid)
library(vip)
```

## Introduction 
In this assignment we carry out an analysis of a dataset containing information of about 40 thousand real estates sold in Iceland from 2008 to 2018. The origin of the data can be traced to the National Registry of Iceland which performs an evaluation of properties worth every year. The data is from 2019 so the current property worth will be referred to simply as property worth. 

  The first part will explore the data visually. The second part will predict properties worth using the lasso and boosting methods. The third part will predict whether a property is old or new using QDA, logistic regression and random forest. Stick around to see if we cracked the bonus question... 

The original dataset was very high dimensional. Irrelevant variables and observations were excluded. Focus will be on data concerning single-family houses and apartment building located in the Capital Region of Iceland. The resulting dataset contains approximately 35 thousand observations and 17 variables regarding properties worth, municipality, age of construction, property type and property area among other.

```{r}
data <- read_delim("https://www.skra.is/library/Samnyttar-skrar-/Fyrirtaeki-stofnanir/Fasteignamat-2019/gagnasafn_ib_2018.csv", ";", escape_double = FALSE, locale = locale(decimal_mark = ",", 
        grouping_mark = ".", encoding = "ISO-8859-1"), 
    trim_ws = TRUE)
data <- data %>% select(kdagur, nuvirdi, byggar, lyfta, ibm2, fjhaed, fjbilsk, fjbkar, fjsturt, fjklos, fjeld, fjherb, fjstof, fjgeym, matssvaedi, ibteg, svfn) %>%
  filter(matssvaedi < 1000) %>%
  mutate(lyfta = ifelse(lyfta >= 1, 1, 0)) %>%
  mutate(ibteg = ifelse(ibteg == 11, 1, 0)) %>%
  mutate_at("lyfta", factor) %>%
  mutate_at("matssvaedi", as.character) %>%
  mutate_at("ibteg", factor) %>%
  na.omit()
         
data$svfn <- recode_factor(data$svfn, `0000` = "Reykjavik", `1000`= "Kopavogur", `1100` = "Seltjarnarnes",`1300` = "Gardabaer", `1400` = "Hafnarfjordur", `1604` = "Mosfellsbaer")
data$kdagur <- as.Date(data$kdagur, format = "%d.%m.%Y")
data$yearkeypt <- format(data$kdagur, format="%Y")
data$yearkeypt <- as.numeric(data$yearkeypt)
data$age <- (as.numeric(data$yearkeypt)-data$byggar)
data <- select(data, -kdagur, -byggar)
data$matssvaedi <- recode_factor(data$matssvaedi, `11`="Rvk:Vesturbær", `20` = "Rvk:Miðbær", `25`="Rvk:Miðbær", `31`="Rvk:Miðbær", `70`="Rvk:Vesturbær", `72`="Rvk:Vesturbær", `75`="Rvk:Vesturbær", `80`="Rvk:Hlíðar", `85`="Rvk:Bústaðarhverfi", `90`="Rvk:Laugardalur", `91`="Rvk:Bústaðarhverfi", `100`="Rvk:Laugardalur", `110`="Rvk:Grafarvogur", `120`="Rvk:Grafarvogur", `130`="Rvk:Grafarvogur", `140`="Rvk:Grafarvogur", `150`="Rvk:Breiðholt", `160`="Rvk:Breiðholt", `161`="Rvk:Breiðholt", `170`="Rvk:Breiðholt", `180`="Rvk:Grafarholt", `181`="Rvk:Grafarholt", `200`="Rvk:Árbær", `210`="Rvk:Árbær", `220`="Rvk:Árbær", `270`="Rvk:Árbær", `280`="Rvk:Bústaðarhverfi", `281`="Rvk:Bústaðarhverfi", `282` ="Rvk:Bústaðarhverfi", `283`="Rvk:Bústaðarhverfi", `284`="Rvk:Bústaðarhverfi", `290`="Rvk:Kjalarnes",
                                 `300`="Kóp:Vesturbær",`320`="Kóp:Austurbær",`330`="Kóp:Smárar", `340`="Kóp:Lindir", `350`="Kóp:Hvörf",`351`="Kóp:Kórar",
                                 `400`="Seltjarnarnes", `500`="Grb:Miðbær", `510`="Grb:Ásar", `511`="Grb:Arnarnes", `520`="Grb:Sjáland", `530`="Grb:Hraunholt", `540`="Grb:Arnarnes", `550`="Grb:Urriðarholt", `560`="Grb:Flatir", `590`="Grb:Annað",`700`="Grb:Álftanes", `600`="Hfj:Miðbær", `620`="Hfj:Holt", `630`="Hfj:Vellir", `640`="Hfj:Ásland", `650`="Hfj:Setberg", `660`="Hfj:Flensborg", `670`="Hfj:Vellir", `680`="Hfj:Holt", `800`="Mos:Miðbær", `810`="Mos:Teigar", `820`="Mos:Leirvogstunga", `830`="Mos:Dalur", `840`="Mos:Hlíðar", `850`="Mos:Helgafell", `890`="Mos:Annað", `999`="Kóp:Annað")

library(Hmisc)
var.labels <- c(nuvirdi = "Prop.Worth", lyfta="Elevator", ibm2 = "Sqm", fjhaed = "Floors", fjbilsk = "Parking", fjbkar = "Bathtubs", fjsturt = "Showers", fjklos="Toilets", fjeld = "Kitchens", fjherb="Rooms", fjstof = "Liv.Rooms", fjgeym = "Storage", matssvaedi = "Neighbourhood", ibteg = "Prop.Type", svfn = "Municipality", yearkeypt = "Salesyear", age = "Age", fermetraverd = "Price-per-Sqm", svfnMosfellsbaer = "Mosfellsbær", svfnHafnarfjordur = "Hafnarfjörður", svfnSeltjarnarnes = "Seltjarnarnes", svfnGardabaer = "Garðabær", svfnKopavogur = "Kópavogur", ibteg1 = "Single-family", ibteg0 = "Apartment", lyfta1 = "Yes", lyfta0 = "No")
```

## Part I: Exploratory Analysis

In this part we will visually explore the data. Property worth is an important variable in our dataset and we are interested in exploring the relationship it has with the other variables in our data set. 

```{r, fig.align='center'}
#color theme
ColorsDT <-  data.table(Group=LETTERS[1:50], Color=c("#e0bba8","#d6a78e","#cd9274", "#c37e59","#b86a41","#9d5b38","#834c2f","#693c25","#4e2d1c","#341e12","#efc699","#eab57a", "#e5a45b","#e1923c","#d88121","#b96e1c","#9a5c17","#7b4912","#5c370e","#3d2409","#d6bdb2", "#caa99a","#bd9583","#b1816c","#a36e56","#8c5e4a","#744e3d","#5d3f31","#462f25","#2e1f18", "#e8bda0","#e1a983","#da9566","#d48149","#ca6e2f","#ad5e28","#904e22","#733f1b","#562f14", "#391f0d","#d9bfae","#ceab96","#c3987d","#b88465","#aa714e","#926143","#7a5138","#61412d", "#493021","#302016"), key="Group")
set.seed(4)
#núvirði skoðað útfrá:
#(1)svfn
f1 <- data %>% ggplot(aes(x=nuvirdi/1e3,y=svfn, fill=svfn)) +
  geom_density_ridges_gradient() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        legend.position = "none") + 
  scale_x_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,100), breaks=seq(0,100,by=50)) +
  scale_fill_manual(values=ColorsDT$Color) + 
  labs(y = " ", x = "Property worth")
#(2)matssvaedi
f2 <- data %>% ggplot(aes(x=nuvirdi/1e3,y=matssvaedi, fill=svfn)) +
  geom_density_ridges_gradient() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        legend.position = "none") + 
  ggtitle(" ") +   
  scale_x_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,100), breaks=seq(0,100,by=50)) +
  scale_fill_manual(values=ColorsDT$Color) + 
  labs(y = " ", x = "Property worth")
grid.arrange(f1,f2,nrow=1,top="Figure 1: Property worth based on municipality and neighbourhood")

ghhh <- data %>%
  group_by(matssvaedi) %>%
  summarise(mean = mean(nuvirdi))
max <- ghhh %>% slice(which.max(mean))
min <- ghhh %>% slice(which.min(mean))

neigh <- data %>%
  group_by(svfn) %>%
  summarise(mean = mean(nuvirdi))
```

Figure 1 shows the distribution of property worth based on the municipality on one hand, and neighbourhood on the other. They are mostly right skewed. The highest average property worths are in Seltjarnarnes ($\mu \approx$ 52 m.ISK), Garðabær ($\mu \approx$ 49 m.ISK). The lowest in Hafnarfjörður ($\mu \approx$ 35 m.ISK) and Reykjavík ($\mu \approx$ 35 m.ISK). 

  The distribution for Seltjarnarnes differs from the rest in both graphs. It is the only multimodal distribution compared to the other municipalities, and has a flatter curve compared to the other neighbourhoods. The property worths in the Flatir neighbourhood in Garðabær is the only left-skewed distribution.   
  
  Properties with the highest average worth, based on neighbourhoods, are in Flatir ($\mu \approx$ `r round(max[2]/1e3,2)` m.ISK) and the lowest are located outside the urbanized area of Kópavogur ($\mu \approx$ `r round(min[2]/1e3,2)` m.ISK). 
  
```{r, fig.align = 'center'}
#(3)yearkeypt
data %>% 
  ggplot(aes(x=nuvirdi/1e3,y=as.factor(yearkeypt), fill=as.factor(yearkeypt))) +
  geom_density_ridges_gradient() +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        legend.position = "none", plot.title = element_text(hjust = 0.5)) + 
  ggtitle(" ") + scale_x_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,100), breaks=seq(0,100,by=20)) + 
  scale_fill_manual(values=ColorsDT$Color) + 
  labs(y = " ", x = "Property worth") + 
  ggtitle("Figure 2: Property worth by year of sale")
```

Figure 2 shows a gradual increase in property worths, and their variability, over the years. The average property worth over the years 2012 to 2018 is approximately 37 m.ISK. This 

```{r, fig.align = 'center'}
#(4)fj breytunar
ff <- function(x){
data %>%
  group_by(bla = as.factor(x)) %>%
  summarise(worth = round(mean(nuvirdi/1e3))) %>% 
   mutate(Label=paste0(worth), "m.ISK") %>%
  ggplot(aes(x=worth,y=bla, fill=bla)) + 
    geom_col() +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), 
          legend.position = "none") +
    scale_fill_manual(values=sample(ColorsDT$Color)) + geom_text(aes(label=worth), nudge_x = -10, col = "white")
}
p <- scale_x_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,200))
q <- scale_x_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,140), breaks = seq(0,140,by=65))
grid.arrange(ff(data$fjhaed)+ 
               labs(y = "Floors", x = " ")+p, ff(data$fjbilsk) + 
               labs(y = "Parking spaces", x = " ")+p, ff(data$fjbkar) + 
               labs(y = "Baths", x = " ")+p, ff(data$fjsturt) + 
               labs(y = "Showers", x = " ")+p, ff(data$fjklos) + 
               labs(y = "Toilets", x = " ")+p, ff(data$fjeld) + 
               labs(y = "Kitchens", x = " ")+p, top= "Figure 3: Mean property worth by various elements")
grid.arrange(ff(data$fjstof) + 
               labs(y = "Living Rooms", x = " ")+q, ff(data$fjgeym) + 
               labs(y = "Storage Rooms", x = " ")+q, ff(data$fjherb) + 
               labs(y = "Rooms", x = " ")+q, nrow=1)
```

Figure 3 shows property worth based on various elements. In general, these elements seem to have a positive linear relationship with property worth. Where number of living rooms, storage rooms and rooms, seem to be an exception where the relationship has a clear curve.

```{r, fig.align = 'center'}
#(5)íbuðir með/án lyftu (bara fjölbýlishús)
# búum til nýtt gagnasafn sem inniheldur bara fjölbýlishús
data %>% filter(ibteg == 0) %>%
  mutate(lyfta = ifelse(lyfta == 1, "Yes", "No")) %>%
  group_by(svfn, lyfta) %>%
  summarise(nuvirdi=mean(nuvirdi)) %>%
  ggplot() + geom_bar(aes(y=nuvirdi/1e3,x=svfn, fill=lyfta), stat= "identity", position = "dodge") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank()) + 
  ggtitle("Figure 4: Average apartment worths by municipality and elevator status") + 
  scale_y_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,45), breaks=seq(0,45,by=10)) + 
  scale_fill_manual(name = "Elevator", values=sample(ColorsDT$Color)) + 
  labs(x = " ", y = "Apartment worth") + 
  annotate(geom="text", y=20,x="Reykjavik", label= "+9%", col="white")+ 
  annotate(geom="text", y=20,x="Kopavogur", label= "+7%", col="white")+ 
  annotate(geom="text", y=20,x="Seltjarnarnes", label= "+0%", col="white")+ 
  annotate(geom="text", y=20,x="Gardabaer", label= "+10%", col="white")+ 
  annotate(geom="text", y=20,x="Hafnarfjordur", label= "+8%", col="white")+ annotate(geom="text", y=20,x="Mosfellsbaer", label="+13%", col="white")
```

Figure 4 shows the average apartment worth, in each municipality, based on whether there is an elevator or not. Apartments in buildings with an elevator are on average worth more. The percentages on the plot represent the increase in worth for having an elevator in the building. Seltjarnarnes is the only municipality where having an elevator does not increase the apartment worth.  

```{r, fig.align = 'center'}
# verð út frá aldri byggingar og tegund húsnæðis.
data %>% 
  mutate(ibteg=ifelse(data$ibteg == 1, "Single-family house", "Apartment building")) %>%
  ggplot(aes(x=nuvirdi/1e3,y=age, group = ibteg, color = ibteg)) +
  geom_smooth() + 
  ggtitle("Figure 5: Property worth based on age and type") +
  labs(x = "Worth", y = "Age") + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), 
        plot.title = element_text(hjust = 0.5),
        legend.position = "top") +
   scale_x_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,100), breaks=seq(0,100,by=25)) + 
  scale_y_continuous(labels = label_number(suffix = " years"), limits=c(0,100), breaks=seq(0,100,by=25)) + 
    scale_color_manual(name = "Type",values = sample(ColorsDT$Color))
```

Figure 5 shows the average property worth based on age and type. As expected, single-family houses are on average worth more than apartment buildings and the property worth decreases with as it ages. Age appears to become irrelevant for single-family houses worth 50 m.ISK and above.   

```{r, fig.align = 'center'}
# worth per square meter by municipality
data %>% 
  mutate(fermetraverd = nuvirdi/ibm2) %>%
  ggplot(aes(x = fermetraverd, y = svfn, fill = svfn)) +
  geom_density_ridges_gradient() +
  labs(x= "Worth per square meter", y = " ") +
  ggtitle("Figure 6: Worth per square meter by municipality") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.position = "none") + 
  scale_fill_manual(values = sample(ColorsDT$Color)) + 
  scale_color_manual(name = "Type of property",values=sample(ColorsDT$Color)) +
  scale_x_continuous(limits=c(0,1000))
```

Figure 6 shows property worth per square meter by municipality. Worths per square meter are a bit higher for properties in Garðabær and Seltjarnarnes (and Mosfellsbær to a degree) than for properties in the other municipalities. 

```{r, fig.align = 'center'}
# fjölbýli vs einbýli eftir municipality. Figure 7
data %>% 
    mutate(ibteg = ifelse(data$ibteg == 1, "Single-family house", "Apartment building"))%>%
  group_by(svfn,ibteg) %>%
  summarise(count=n()) %>%
  ggplot(aes(fill = ibteg, x = svfn, y=count)) + 
  geom_bar(stat= "identity", position = "dodge") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.position = c(0.7,0.7) ,
      legend.direction = "horizontal") + 
  ggtitle("Figure 7: Property type by municipality") +
  scale_fill_manual(name = "Property type", values=sample(ColorsDT$Color)) + 
  labs(x = " ", y = "Total") + ylim(0, 17000) + 
  annotate(geom="text", y=1000, x="Reykjavik", label="81%", col="black")+ 
  annotate(geom="text", y=1000, x="Kopavogur", label="77%", col="black")+ 
  annotate(geom="text", y=1000, x="Seltjarnarnes", label="62%", col="black")+ 
  annotate(geom="text", y=1000, x="Gardabaer", label="61%", col="black")+ 
  annotate(geom="text", y=1000, x="Hafnarfjordur", label="68%", col="black")+ 
  annotate(geom="text", y=1000, x="Mosfellsbaer", label="49%", col="black")
```

Figure 7 shows the split of property types for each municipality. The plot shows the percentage of apartment buildings.   

```{r, fig.align = 'center'}
#Corrplot allar numeric breytur
da <- data %>%
  dplyr::select(where(is.numeric))
colnames(da) <- as.list(var.labels[match(names(da),names(var.labels))])
par(xpd=TRUE)
corrplot.mixed(cor(da), lower.col = "#d88121", number.cex=0.7, tl.pos = "lt", upper.col = "#8c5e4a", tl.col="#341e12", tl.cex=0.7, tl.srt = 45, title = "Figure 8: Correlation plot of property elements", mar=c(0,0,4,0))
```

Figure 8 shows correlation of all numeric (14) property elements of the dataset. Property worth has a moderately strong positive correlation with the size of properties (in square meters), year of sale and number of rooms, living rooms, floors, showers and toilets in a property. 

The last five attributes mentioned here above also appear to have a moderately strong postive relationship with each other. 

## Part II: Predicting property worth

In this part we will predict sale worths using the lasso and boosting methods. 
We will start by doing a factor analysis of the dataset to get a better idea of its nature.

#### Factor analysis
```{r}
set.seed(4)
colnames(data) <- as.list(var.labels[match(names(data),names(var.labels))])
blabb <- data %>% select(-Neighbourhood)
library(FactoMineR)
library(factoextra)
#res.famd1 <- FAMD(data, sup.var=data$Prop.Worth, graph=F, ncp=10)
#lkj1 <- get_famd_var(res.famd1)$cos2
#round(lkj1,2)
#corrplot(lkj1)
```

Factor analysis on the data set as a whole obtained 25 dimensions all with eigenvalues higher than one, indicating that the dimension accounts for more variance than one of the original variables. These 25 dimensions only collectively explained around 66% of data variance. Neighbourhood had no correlation to any dimensions so it will be removed for further analysis. 

```{r fig.align = 'center'}
res.famd <- FAMD(blabb,
                 sup.var=blabb$Prop.Worth,
                 graph=F,
                 ncp=10)
baa <- data.frame(get_eigenvalue(res.famd))
rownames(baa) = c(1:10)
ba <- baa[1:7,] 
ba %>%
  ggplot() + geom_col(aes(x=rownames(ba), y=ba$variance.percent, fill=rownames(ba)))+
  geom_point(aes(x=rownames(ba), y=ba$cumulative.variance.percent, col=rownames(ba))) +
  labs(x= "Dimensions", y = "Variance explained") +
  ggtitle("Figure 9: Factor Analysis of Mixed Data") + 
  theme(plot.title = element_text(hjust = 0.5)) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.position = "none") + 
  scale_fill_manual(values = sample(ColorsDT$Color)) + 
  scale_color_manual(values=sample(ColorsDT$Color)) + 
  scale_y_continuous(labels = label_number(suffix = "%"), limits=c(0,80))  + 
  annotate(geom="text", y=3,x="1", 
           label= paste(round(ba$variance.percent[1]),"%"), col="white") +
  annotate(geom="text", y=3,x="2", 
           label= paste(round(ba$variance.percent[2]),"%"), col="white") + 
  annotate(geom="text", y=3,x="3", 
           label= paste(round(ba$variance.percent[3]),"%"), col="white") +
  annotate(geom="text", y=3,x="4", 
           label= paste(round(ba$variance.percent[4]),"%"), col="white") + 
  annotate(geom="text", y=3,x="5", 
           label= paste(round(ba$variance.percent[5]),"%"), col="white") + 
  annotate(geom="text", y=3,x="6", 
           label= paste(round(ba$variance.percent[6]),"%"), col="white") +
  annotate(geom="text", y=3,x="7", 
           label= paste(round(ba$variance.percent[7]),"%"), col="white") + 
  annotate(geom="text", y=25,x="1", 
           label= paste(round(ba$cumulative.variance.percent[1]),"%"), col="#a36e56") +
  annotate(geom="text", y=38,x="2", 
           label= paste(round(ba$cumulative.variance.percent[2]),"%"), col="#a36e56") + 
  annotate(geom="text", y=45,x="3", 
           label= paste(round(ba$cumulative.variance.percent[3]),"%"), col="#a36e56") +
  annotate(geom="text", y=51,x="4", 
           label= paste(round(ba$cumulative.variance.percent[4]),"%"), col="#a36e56") + 
  annotate(geom="text", y=56,x="5", 
           label= paste(round(ba$cumulative.variance.percent[5]),"%"), col="#a36e56") + 
  annotate(geom="text", y=62,x="6", 
           label= paste(round(ba$cumulative.variance.percent[6]),"%"), col="#a36e56") +
  annotate(geom="text", y=67,x="7", 
           label= paste(round(ba$cumulative.variance.percent[7]),"%"), col="#a36e56") 
```

  Figure 9 shows the relative and cumulative variance explained by the factor analysis dimensions. Removing the two variables reduced the dimensions from 25 to seven and only decreased the cumulative variance explained by around 2%. According to the factor analysis the most influential variables are municipality, sqm, sales year, property worth, and number of bathtubs. 
  
  The first dimension consisted of property worth, sqm, floors, toilets, rooms, living rooms, and property type (where sqm is clearly most influental), together they might be representing property size. The second consisted of age, parking, and elevator status. The third consists of number of bathtubs and showers, together might represent the number of master bathrooms. Sales year and storage have it's own dimension. The factor analysis showed that municipality had substantially higher contribution rate compared to the other variables and works as multiple seperate dimensions, two of which are included in the seven dimensions. 

#### The lasso

```{r, fig.align = 'center'}
x <- model.matrix(Prop.Worth~., blabb)[,-1]
grid <- 10^seq(4,-1, length.out = 10)
train <- sample(1:nrow(x),nrow(x)*0.7)
Tr <- blabb[train,]
y <- Tr$Prop.Worth
lasso.cv <- cv.glmnet(x[train,],
                      y,
                      alpha=1,
                      lambda = grid)
bestlam <- lasso.cv$lambda.min
bestmse <- min(lasso.cv$cvm)
data.frame(lambda = lasso.cv$lambda, 
           cv.mse = lasso.cv$cvm, 
           nonzero = lasso.cv$nzero) %>%
  ggplot(aes(x = lambda, y = cv.mse,
             col = ifelse(lambda==bestlam, "#493021","#d88121"))) + 
  geom_point(size=3) + 
  geom_line() +
  scale_x_log10(breaks = trans_breaks("log10", function(x) 10^x),
               labels = trans_format("log10", math_format(10^.x))) +
  scale_y_log10(breaks = trans_breaks("log10", function(x) 10^x),
               labels = trans_format("log10", math_format(10^.x))) +
  scale_color_identity() + xlab( expression(lambda)) + ylab("Cross-Validation MSE") +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.position = "none", plot.title = element_text(hjust = 0.5)) + 
  ggtitle("Figure 10: Lasso Cross-Validation") + 
  annotate(geom="text",y=10^(0.03+log10(bestmse)), x=10^log10(bestlam), label= expression(paste(lambda, "=0.36")))
```

Figure 10 shows the test MSE for a range of $\lambda$ values via cross-validation. Where it was optimal at `r round(bestlam,2)`. 

```{r, fig.align = 'center'}
library(reshape2)
lasso.mod <- glmnet(x[train,],
                    y,
                    alpha=1,
                    standardize = T,
                    metric="mse",
                    lambda = bestlam)
vi(lasso.mod) %>% ggplot(aes(Importance, reorder(Variable,Importance),
             fill = Sign)) +
  geom_bar(stat = "identity", position = "dodge")+ 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.direction = "horizontal", legend.position = c(0.7,0.7)) + 
  scale_fill_manual(values=sample(ColorsDT$Color)) + labs(x="Beta coefficient", y=" ") + ggtitle(expression(paste("Figure 11: Predictors with non-zero Lasso coefficients with ", lambda, " = 0.36")))

test <- blabb[-train,]
lasso.pred <- predict(lasso.mod, s=bestlam, newx=x[train,])
lasso.trainmse <- round(mean(lasso.pred[,1])/1e3,2)
lasso.pred. <- predict(lasso.mod, s=bestlam, newx=x[-train,])
lassomse. <- round(mean(lasso.pred.[,1])/1e3,2)
#test R squared
r2.lasso <- percent(1-mean((lasso.pred.[,1]-test$Prop.Worth)^2)/mean((mean(test$Prop.Worth)-test$Prop.Worth)^2))
#train R squared
r2train.lasso <- percent(lasso.mod$dev.ratio)

lasso.trainmseNew <- log10(round(mean(lasso.pred[,1]),2))
lassomse.new <- log10(round(mean(lasso.pred.[,1]),2))
```

  Figure 11 shows the `r nrow(vi(lasso.mod))` predictors that Lasso deemed influental regarding property worth. The model explained around `r r2.lasso` of property worth variance ($R^2$). With training error around `r lasso.trainmseNew` and test error around `r lassomse.new`. 
  
```{r, fig.align = 'center'}
gaga <- cbind(lasso.pred,y)
gaga <- as.data.frame(gaga)
colnames(gaga) <- c("pred", "true")
g1 <- gaga %>%
  ggplot(aes(x=pred/1e3,y=true/1e3)) + geom_point(col = "#e0bba8")+ 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.position = "none") +  labs(y=" ", x=" ") + 
        geom_abline(slope=1,intercept = 0,lty=2, col= "#302016") +
scale_x_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,150)) +
  scale_y_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,150))
g2 <- gaga %>%
  ggplot(aes(x=pred/1e3,y=true/1e3)) + geom_point(col = "#e0bba8")+ 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.position = "none") +  labs(y=" ", x=" ") + 
        geom_abline(slope=1,intercept = 0,lty=2, col= "#302016") +
scale_x_continuous(labels = label_number(suffix = " m.ISK"), limits=c(0,150),breaks = seq(0,150, by=50)) +
  scale_y_continuous(labels = label_number(suffix = " m.ISK"))
grid.arrange(g2,g1, nrow=1,top="Figure 12: Lasso predicted versus observed property worth", bottom="Predicted", left="Observed")
```

In Figure 12 we see the relationship between lasso´s predicted values and observed values. The right graph includes all values in the data set and we appear to have an extreme value at the top of the plot. 
  The left graph is a close-up of all the values excluding the extreme value. The relationship seems stronger for lower worth properties but starts to gradually worsen as the worth rises.

#### Boosting

```{r}
set.seed(1)
datam <- data %>% select(-Neighbourhood)
TRAIN <- sample(1:nrow(datam), nrow(datam)*0.7)
train.set <- datam[TRAIN,]
test.set <- datam[-TRAIN,]

trainctrl <- trainControl(method = "repeatedcv", number = 5)

myBestGrid2 <- data.frame("n.trees" = 500,"interaction.depth"= 10,"shrinkage"=0.1,"n.minobsinnode"=10)

gbm_tree_final <- train(Prop.Worth ~ ., data = train.set, 
                        method="gbm", 
                        distribution = "gaussian", 
                        trControl = trainctrl, 
                        verbose = FALSE, 
                        tuneGrid = myBestGrid2)

```

We ran cross-validation on multiple combinations of trees. 
Tuning the parameters resulted in a model with 500 boosting iterations (n.trees = 500), a max tree depth of ten (interaction depth = 10), and a $\lambda$ of 0.1. The minimum terminal node size was kept constant at 10. 

```{r fig.align='center'}
knitr::include_graphics("https://i.imgur.com/lOfx4DZ.png")
```
In figure 13 we see a plot of the RMSE via cross-validation according to various measures of tree size and shrinkage value. We can see here that using 500 boosting iterations, with $\lambda$ of 0.1 and a max tree depth of 10 results in the lowest RMSE out of all the tree combinations that were created. 

```{r fig.align = 'center'}
NewBoost.predict <- predict(gbm_tree_final, newdata = test.set)

#which variables are most important. 
boost <- vip(gbm_tree_final, aesthetics = list(fill = c("#d48149","#da9566","#ca6e2f","#ad5e28","#e1a983","#e8bda0","#2e1f18",
                                      "#462f25","#5d3f31","#904e22")),
    mapping = aes_string(fill = "Variable")) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        plot.title = element_text(hjust = 0.5)) + 
  labs(x = " ", y = "Relative influence") 
boost + ggtitle("Figure 14: Relative influence of variables using boosting") 

#What is the test MSE
BOOST.test.MSE <- log10(round(mean((NewBoost.predict - test.set$Prop.Worth)^2), 2))

# Reiknað út RMSE

rmse.boost <- log10(sqrt(BOOST.test.MSE))
```

As shown in figure 14, there are three variables that have higher relative importance. They are square meters of property, the year the property was bought and the age of the property. Square meters per property is by far the most important variable. In figures 5 and 8 in the exploratory analysis we learned that the more square meters are in a property the more it is worth and that property worth increases the younger the property is. 

```{r fig.align='center'}
library(Metrics)

lasso.testMSE <- log10(round((mean(lasso.pred.[,1])^2),2))
lasso.RMSE <- log10(round(sqrt(lasso.testMSE), 2))

famd <- data.frame(get_famd_var(res.famd)$contrib)
famd <- data.frame(apply(famd,1,sum)) %>%
  mutate(Variable= rownames(famd))
lass <- vi(lasso.mod)
boos <- vi(gbm_tree_final)
com <- merge(lass,boos, by="Variable")
com <- merge(com,famd, by="Variable")
lasso <- com %>% ggplot(aes(Importance.x,Variable,
             fill = Sign)) +
  geom_bar(stat = "identity")+ 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.position = c(0.8,0.8)) +
  scale_fill_manual(values=sample(ColorsDT$Color)) + labs(x="Beta coefficient", y=" ") + ggtitle("Lasso") + 
  annotate(geom="text",y="Liv.Rooms", x=6000, label= paste0("MSE= log10(", round(lasso.testMSE, 2),")"), size=3) + 
  annotate(geom="text",y="Kitchens", x=6000, label= paste0("RMSE= log10(", round(lasso.RMSE, 2),")"), size=3)
boost <- com %>% ggplot(aes(Importance.y,Variable,
                            fill=Variable)) +
  geom_bar(stat = "identity")+ 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.position = "none",
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  scale_fill_manual(values=sample(ColorsDT$Color)) + labs(x="Relative Influence", y=" ") + ggtitle("Boosting") + 
  annotate(geom="text",y="Kitchens", x=50, label= paste0("MSE= log10(", round(BOOST.test.MSE, 2),")"), size=3) + 
  annotate(geom="text",y="Floors", x=50, label= paste0("RMSE= log10(", round(rmse.boost, 2),")"), size=3)
faa <- com %>% ggplot(aes(apply.famd..1..sum.,Variable,
                          fill=Variable)) +
  geom_bar(stat = "identity")+ 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        panel.background = element_blank(), legend.position = "none",
        axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
  scale_fill_manual(values=sample(ColorsDT$Color)) + labs(x="Relative Influence", y=" ") + ggtitle("Factor Analysis")
grid.arrange(lasso, boost, faa, nrow=1, top="Figure 15: Comparison of Lasso, Boosting, and Factor Analysis") 

```

In Figure 15 we can see the results from both the lasso approach and boosting. The MSE and RMSE for boosting is lower than it is for Lasso. Additionally it includes 10 variables while Lasso has 19. The approaches do not seem to evaluate the variables the same way, the only one that seems consistantly influential is the sales year. 

  Boosting evaluated square meter as the most influential variable. Lasso did not null it out but was second lowest of the remaining variables. That variable had the highest correlation to the first dimension obtained by the factor analysis. From this we might assume that square meter is influential regarding property worth, but as an confounding variable. Which is Lasso's weakpoint. 

## Part III: Predicting whether a property is old or new

Here we will predict whether a property is old or new. We've created a new binary variable: If the property age exceeds the overall median age (32 years) it is categorised as an old property, and the remaining as new properties. 

We will use quadratic discriminant analysis (QDA), logistic regression and random forest to predict whether a property is old or new.

```{r}
# Búum til nýtt gagnasafn. Breytum breytunni AGE í factor breytu. Tekur gildið 1 = ný bygging, 0 = gömul bygging. Út frá miðgildi AGE. 
set.seed(1)
data2 <- data %>% mutate(AgeNew = (ifelse(Age < 32, 1, 0))) %>% 
  select(-Age, -Neighbourhood) %>%
  mutate_at("AgeNew", factor)
  # sjá colSums(is.na(data)) 
#Skiptum aftur í training og test set. 
train2 <- sample(1:nrow(data2), nrow(data2)*0.7)
train.set2 <- data2[train2,]
test.set2 <- data2[-train2,]
```

#### Quadratic discriminant analysis

```{r}
library(MASS)
QDA.fit <- qda(AgeNew ~ ., data = train.set2)
QDA.pred <- predict(QDA.fit, test.set2)
#QDA.fit # hvaða upplýsingar fáum við úr þessu outputti? 
# Lets look at the confusion matrix for LDA to see how well the LDA fit works with the test.set
kabletable <- table(QDA.pred$class,test.set2$AgeNew)
rownames(kabletable) <- c("Old", "New")
colnames(kabletable) <- c("Old","New")
kbl(kabletable,booktabs=T, caption = "Table 1: Quadratic discrimnant analysis") %>% 
  kable_styling(full_width = F, position = "center") %>%
  add_header_above(c(" ","True values" = 2),bold=T) 

meanQDA <- round(1-(mean(QDA.pred$class == test.set2$AgeNew)), 2)
meanQDAperc <- percent(meanQDA)
```

The test error rate of the LDA model is  `r meanQDA`, meaning the model predicted incorrectly nearly  `r meanQDAperc` of the time. 

#### Logistic regression 
```{r}
LOG.fit <- glm(AgeNew ~ ., data = train.set2,
               family = "binomial")
#summary(LOG.fit) #segir okkur hvaða coefficients eru marktækir
LOG.prob <- predict(LOG.fit, newdata = test.set2, 
                    type = "response")
LOG.pred <- rep(0, nrow(test.set2))
LOG.pred[LOG.prob > 0.5] <- 1 #define values as 1 (new property) if probs are above 0.5. 

kabletable2 <- table(LOG.pred, test.set2$AgeNew)
rownames(kabletable2) <- c("Old", "New")
colnames(kabletable2) <- c("Old", "New")
kbl(kabletable2,booktabs=T, caption = "Table 2: Logistic Regression") %>% 
  kable_styling(full_width = F, position = "center") %>%
  add_header_above(c(" " = 1, "True values" = 2))
  
meanLOG <- round(1-(mean(LOG.pred == test.set2$AgeNew)), 2)
meanLOGperc <- percent(meanLOG)

detach("package:MASS", unload=TRUE)
```

The test error rate of the LDA model is  `r meanLOG`, meaning the model predicted incorrectly nearly  `r meanLOGperc` of the time. Similar result to that of QDA.   

#### Random forests

```{r fig.align='center'}
# randforr_MSE <- rep(NA,ncol(train.set2)-1)
# #þessi skipun tekur um 10 min að keyra í minni tölvu. 
# 
# for (i in 1:(ncol(train.set2)-1)) {
#   randforr_cs <- randomForest(AgeNew~.,data=train.set2,mtry=i,importance=T)
#   pred_randforr <- predict(randforr_cs,newdata = test.set2)
#   randforr_MSE[i] <- mean((pred_randforr==test.set2$AgeNew))
#   
#   print("Höfum keyr í gegn")
#   print(i)
#   print("sinnum")
#                                                         #==================================================================
# }                                                       #Þetta er cross validation fallið en það tekur ár og öld að keyra
#randforr_MSE                                             #Uncomment at your own risk !!!!!!!!!!
#                                                         #==================================================================
# randforr_MSE_calc <- abs(randforr_MSE-1)

randforr_list_MSE <- c(0.1986711, 0.1682962, 0.1576649, 0.1521595, 0.1497864,0.1489321,0.1482677,0.1463692,0.1483626,0.1464642, 0.1492169, 0.1487423, 0.1510204,0.1506407, 0.1533935) 

best.mtry <- which.min(randforr_list_MSE)
min.testMSE <- round(0.1463692, 2)

Degrees <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15)

randforr_list_MSE.DF <- data.frame(Degrees, randforr_list_MSE)
colnames(randforr_list_MSE.DF) <- c("Degrees", "TestMSE")

randforr_list_MSE.DF %>% ggplot() + 
  geom_point(aes(x = Degrees , y = TestMSE), col = "#3d2409", size = 3) + 
  geom_point(aes(x=best.mtry, y = randforr_list_MSE[best.mtry]), shape = 10, col = "#e1923c", size = 70) +
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        legend.position = "none", plot.title = element_text(hjust = 0.5)) + 
  labs(x="Degrees", y = "Test MSE") + 
  ggtitle(expression(paste("Figure 16: Test MSE by varying degrees"))) + 
  xlim(1, 15) + 
  ylim(0.14, 0.20)
```

In figure 16 we see the test MSE by varying degrees of variables used to make the tree. The lowest test MSE can be found when using 8 variables and the corresponding test MSE is `r round(min.testMSE, 2)`.


```{r fig.align='center'}
library(vip)
#library(rpart)   # tveir tree plot pakkar 
#library(visreg)  # Sjáum hvort það sé tími til að nota þá. 

randforr_best <- randomForest(AgeNew ~ ., data = train.set2,
                              mtry = best.mtry,
                              importance = T,
                              ntree = 500)

pred_randforr_best <- predict(randforr_best,
                              newdata = test.set2)


#backup: min.testMSE <- round(0.1463692, 2)

#which variables are most important. 
vip(randforr_best, aesthetics = list(fill = c("#d48149","#da9566","#ca6e2f","#ad5e28","#e1a983","#e8bda0","#2e1f18",
                                      "#462f25","#5d3f31","#904e22")),
    mapping = aes_string(fill = "Variable")) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        plot.title = element_text(hjust = 0.5)) + 
  ggtitle("Figure 17: Relative influence of variables using random forest") + 
  labs(x = " ", y = "Relative influence") 
```

The results on figure 17 indicate that across all of the trees considered in the random forest, municipality is by far the most important variable when it comes to predicting the age of a property (old or new). Other important variables are number of garages, whether there is an elevator in the building and property worth. 

```{r}
kabletableRF <- table(pred_randforr_best, test.set2$AgeNew)
rownames(kabletableRF) <- c("Old", "New")
colnames(kabletableRF) <- c("Old", "New")
kbl(kabletableRF,caption = "Table 3: Random Forest") %>% 
  kable_styling(full_width = F, position = "center") %>%
  add_header_above(c(" " = 1, "True values" = 2)) 

randforr_MSE_best <- round(1-mean((pred_randforr_best==test.set2$AgeNew)),2)
randforr_MSE_bestP <- percent(randforr_MSE_best)
```

The test error rate of the LDA model is  `r randforr_MSE_best`, meaning the model predicted incorrectly nearly  `r randforr_MSE_bestP` of the time. 

```{r}
old <- data.frame(QDA = c(paste0(round(sum(diag(kabletable))/sum(kabletable)*100),"%"),
                          paste0(round(prop.table(kabletable)*100),"%")),
         LR =c(paste0(round(sum(diag(kabletable2))/sum(kabletable2)*100),"%"),
               paste0(round(prop.table(kabletable2)*100),"%")),
         RF = c(paste0(round(sum(diag(kabletableRF))/sum(kabletableRF)*100), "%"), 
                paste0(round(prop.table(kabletableRF)*100), "%")),
         row.names = c("Accuracy","True negatives", "False positives", "False negatives", "True positives"))
old %>%
  kable(caption = "Table 4: Comparison of QDA, LR and Random forest") %>%
  kable_styling(full_width = F)
```

In table 4 we see a comparison of the results between QDA, logistic regression and random forest. Overall, random forest outperforms QDA and logistic regression with the highest percentage of accuracy, true negatives and true positives. QDA and logistic regression have very similar results, although the percentage of false negatives is slightly (but still noticably) higher for QDA.


#### Bonus
```{r fig.align = 'center'}
bonusdataserbyli <- read.csv("https://raw.githubusercontent.com/IndridiArn/Final-Project-HGG-/main/bonusdataserbyli.csv")
bonusdatafjolbyli <- read.csv("https://raw.githubusercontent.com/IndridiArn/Final-Project-HGG-/main/bonusdatafjolbyli.csv")
sam <- names(bonusdatafjolbyli)[names(bonusdatafjolbyli) %in% names(bonusdataserbyli)]
bonusdataserbyli <- bonusdataserbyli %>%
  select_if(colnames(bonusdataserbyli) %in% sam)
bonusdatafjolbyli <- bonusdatafjolbyli %>%
  select_if(colnames(bonusdatafjolbyli) %in% sam)
bonus <- rbind(bonusdatafjolbyli,bonusdataserbyli)

bonus$utgdag <- as.Date(bonus$utgdag, format = "%m/%d/%Y")
bonus$year <- format(bonus$utgdag, format="%Y")
bonus$year <- as.numeric(bonus$year)
bonus <- bonus %>%
  filter(bonus$year>2018)
bonus <- bonus %>% select(nuvirdi, ibm2,fjbilsk,age_studull, year, hverfi)
var.labels <- c(nuvirdi = "Prop.Worth", ibm2 = "Sqm", fjbilsk = "Parking", age_studull = "Age", year = "Salesyear", hverfi = "Neighbourhood")
colnames(bonus) <- as.list(var.labels[match(names(bonus), names(var.labels))])
```

```{r}
set.seed(1)
datam <- data %>% select(Prop.Worth,Sqm,Parking,Age,Salesyear,Neighbourhood)
gbm_tree_final <- train(Prop.Worth ~ ., data = datam, 
                        method="gbm", 
                        distribution = "gaussian", 
                        trControl = trainctrl, 
                        verbose = FALSE, 
                        tuneGrid = myBestGrid2)
```

```{r}
NewBoost.predict <- predict(gbm_tree_final, newdata = bonus)

#which variables are most important. 
boost <- vip(gbm_tree_final, aesthetics = list(fill = c("#d48149","#da9566","#ca6e2f","#ad5e28","#e1a983","#e8bda0","#2e1f18",
                                      "#462f25","#5d3f31","#904e22")),
    mapping = aes_string(fill = "Variable")) + 
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        plot.title = element_text(hjust = 0.5)) + 
  labs(x = " ", y = "Relative influence") 
boost + ggtitle("Figure 18: Relative influence of variables using boosting") 

#What is the test MSE
BOOST.test.MSE <- log10(round(mean((NewBoost.predict - test.set$Prop.Worth)^2), 2))

# Reiknað út RMSE

rmse.boost <- log10(sqrt(BOOST.test.MSE))
```

